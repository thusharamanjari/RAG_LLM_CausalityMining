# RAG-bases-LLM-for-Causality-Mining

### Code for the paper "Retrieval Augmented Generation based Large Language Models for Causality Mining" published in NAACL 2025 Knowledge NLP 

Abstract: 

Causality detection and mining are important tasks in information retrieval due to their
enormous use in information extraction, and
knowledge graph construction. To solve these
tasks, in existing literature there exist several solutionsâ€”both unsupervised and supervised. However, the unsupervised methods
suffer from poor performance and they often require significant human intervention for
causal rule selection, leading to poor generalization across different domains. On the
other hand, supervised methods suffer from
the lack of large training datasets. Recently,
large language models (LLMs) with effective
prompt engineering are found to be effective
to overcome the issue of unavailability of large
training dataset. Yet, in existing literature,
there does not exist comprehensive works on
causality detection and mining using LLM
prompting. In this paper, we present several
retrieval-augmented generation (RAG) based
dynamic prompting schemes to enhance LLM
performance in causality detection and extraction tasks. Extensive experiments over three
datasets and five LLMs validate the superiority
of our proposed RAG-based dynamic prompting over other static prompting schemes.

Figure: 

<img width="646" alt="image" src="https://github.com/user-attachments/assets/1f18cfee-4d71-48be-b426-6dd9a39b81b4" />

Results: 

<img width="649" alt="image" src="https://github.com/user-attachments/assets/3c49bd49-6a42-498a-a6c9-f1a18a4fb28f" />

<img width="496" alt="image" src="https://github.com/user-attachments/assets/ab3bd7ea-4f4c-4d9e-9ca2-ec494640b83f" />

